# -*- coding: utf-8 -*-
"""cv_project1_BOVW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sM8ATDt4LQkVQ6RFxGWTxTgLbJ_gnsrd

# BOVW method on AT & T dataset
"""

import cv2
import numpy as np
import os
from sklearn.metrics import accuracy_score, recall_score, precision_score
from google.colab.patches import cv2_imshow
from google.colab import drive
drive.mount('/content/drive')
path = "/content/drive/MyDrive/computer_vision/project1/AT_T"
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.cluster import KMeans

files_list = []
for root, dirs, files in os.walk(path):
    for f in files:
        files_list.append((os.path.join(root, f)))

train_list = []
train_label = []
test_list = []
test_label = []

for i in files_list:
    temp = i.split(".")[0]
    temp_list = temp.split("/")
    target = temp_list[-2]
    image_no = temp_list[-1]
    if int(image_no) >=9:
        test_list.append(i)
        test_label.append(target)
    else:
        train_list.append(i)
        train_label.append(target)


train_set = set(train_label)
count1 = 0
dict_lab = {}
for i in train_set:
    dict_lab[i] = count1
    count1+=1
for i in range(len(train_label)):
    train_label[i] = dict_lab[train_label[i]]
for i in range(len(test_label)):
    test_label[i] = dict_lab[test_label[i]]


# Load train images and labels
train_images = []
train_labels = []
for i in range(0, len(train_list)):  
    
    img = cv2.imread(train_list[i])

    train_images.append(img)
    label = train_label[i]
    
    train_labels.append(label)
# Load test images and labels
test_images = []
test_labels = []
for i in range(0, len(test_list)):  

    img = cv2.imread(test_list[i])
    test_images.append(img)
    label = test_label[i]
    
    test_labels.append(label)


print("len of train label",len(train_labels))
print("len of train img",len(train_images))
print("len of test label",len(test_labels))
print("len of test img ",len(test_images))


import numpy as np
from sklearn.cluster import KMeans
from sklearn.svm import SVC
import cv2

# Define the number of clusters (visual words)
num_clusters = 50

# Initialize the SIFT feature detector and descriptor
sift = cv2.xfeatures2d.SIFT_create()

# Extract features from the train images
train_features = []
for img in train_images:
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Add the descriptors to the list of features
    train_features.append(des)

# Concatenate the features into a single array
train_features = np.concatenate(train_features)

# Cluster the features into visual words
kmeans = KMeans(n_clusters=num_clusters).fit(train_features)

# Visualize the visual words
visual_words = kmeans.cluster_centers_
plt.figure(figsize=(10, 5))
for i in range(num_clusters):
    plt.subplot(5, 10, i+1)
    plt.imshow(visual_words[i].reshape((8, 16)).astype(np.uint8), cmap='gray')
    plt.axis('off')
plt.tight_layout()
plt.show()

# Extract features from the test images
test_features = []
for img in test_images:
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Add the descriptors to the list of features
    test_features.append(des)

# Convert the test features into visual words
test_visual_words = []
for i in range(len(test_images)):
    img = test_images[i]
    label = test_labels[i]
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Cluster the features into visual words
    words = kmeans.predict(des)
    # Count the occurrences of each visual word
    word_hist, _ = np.histogram(words, bins=num_clusters, range=(0, num_clusters))
    # Normalize the histogram
    word_hist = word_hist / np.sum(word_hist)
    # Add the histogram to the list of visual words
    test_visual_words.append(word_hist)

    # Visualize the intermediate image
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(f"Test Image {i+1}")
    plt.axis('off')
    plt.show()

    # Visualize the SIFT keypoints
    img_kp = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    plt.imshow(cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB))
    plt.title(f"SIFT Keypoints for Test Image {i+1}")
    plt.axis('off')
    plt.show()

    # Visualize the visual word occurrences
    plt.bar(range(num_clusters), word_hist)
    plt.title(f"Visual Words Histogram for Test Image {i+1}")
    plt.xlabel("Visual Word Index")
    plt.ylabel("Occurrences")
    plt.show()


# Train a SVM classifier using the visual words
classifier = SVC(kernel='linear')
classifier.fit(test_visual_words, test_labels)

# Recognize faces in the test images
predictions = []
for visual_words in test_visual_words:
    # Predict the label using the trained classifier
    label = classifier.predict([visual_words])[0]
    # Add the label to the list of predictions
    predictions.append(label)

print("Predictions:",predictions,"\n","Labels:",test_labels)

from sklearn.metrics import accuracy_score
acc=accuracy_score(test_labels, predictions)
print("accuracy is:",acc)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
y_test = test_labels
y_pred = predictions
cm = confusion_matrix(y_test, y_pred)
print("Confusion matrix:")
print(cm)
precision = precision_score(y_test, y_pred,average='macro')
print("Precision:")
print(precision)
recall = recall_score(y_test, y_pred,average='macro')
print("Recall:")
print(recall)
f1_score = f1_score(y_test, y_pred,average='macro')
print("F1 score:")
print(f1_score)

"""# BOVW method on ORL dataset

"""

import cv2
import numpy as np
import os
from sklearn.metrics import accuracy_score, recall_score, precision_score
from google.colab.patches import cv2_imshow
from google.colab import drive
drive.mount('/content/drive')
path = "/content/drive/MyDrive/computer_vision/project1/orl"
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.cluster import KMeans

files_list = []
for root, dirs, files in os.walk(path):
    for f in files:
        files_list.append((os.path.join(root, f)))

print(files_list)

train_list = []
train_label = []
test_list = []
test_label = []


### ['/content/drive/MyDrive/computer_vision/project1/orl/80_8.jpg', '/content/drive/MyDrive/computer_vision/project1/orl/48_5.jpg',
for i in files_list:
    temp = i.split(".")[0]
    temp_list = temp.split("/")[-1].split("_")
    target = temp_list[1]
    image_no = temp_list[0]
    img_rem = int(image_no) % 10
    if img_rem ==0 or img_rem == 9:
        test_list.append(i)
        test_label.append(target)
    else:
        train_list.append(i)
        train_label.append(target)


train_set = set(train_label)
count1 = 0
dict_lab = {}
for i in train_set:
    dict_lab[i] = count1
    count1+=1
for i in range(len(train_label)):
    train_label[i] = dict_lab[train_label[i]]
for i in range(len(test_label)):
    test_label[i] = dict_lab[test_label[i]]


train_images = []
train_labels = []
for i in range(0, len(train_list)):  

    img = cv2.imread(train_list[i])

    train_images.append(img)
    label = train_label[i]

    train_labels.append(label)
# Load test images and labels
test_images = []
test_labels = []
for i in range(0, len(test_list)):  
    
    img = cv2.imread(test_list[i])
    test_images.append(img)
    label = test_label[i]
   
    test_labels.append(label)


print("len of train label",len(train_labels))
print("len of train img",len(train_images))
print("len of test label",len(test_labels))
print("len of test img ",len(test_images))


import numpy as np
from sklearn.cluster import KMeans
from sklearn.svm import SVC
import cv2

# Define the number of clusters (visual words)
num_clusters = 50

# Initialize the SIFT feature detector and descriptor
sift = cv2.xfeatures2d.SIFT_create()

# Extract features from the train images
train_features = []
for img in train_images:
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Add the descriptors to the list of features
    train_features.append(des)

# Concatenate the features into a single array
train_features = np.concatenate(train_features)

# Cluster the features into visual words
kmeans = KMeans(n_clusters=num_clusters).fit(train_features)

# Visualize the visual words
visual_words = kmeans.cluster_centers_
plt.figure(figsize=(10, 5))
for i in range(num_clusters):
    plt.subplot(5, 10, i+1)
    plt.imshow(visual_words[i].reshape((8, 16)).astype(np.uint8), cmap='gray')
    plt.axis('off')
plt.tight_layout()
plt.show()

# Extract features from the test images
test_features = []
for img in test_images:
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Add the descriptors to the list of features
    test_features.append(des)

# Convert the test features into visual words
test_visual_words = []
for i in range(len(test_images)):
    img = test_images[i]
    label = test_labels[i]
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Cluster the features into visual words
    words = kmeans.predict(des)
    # Count the occurrences of each visual word
    word_hist, _ = np.histogram(words, bins=num_clusters, range=(0, num_clusters))
    # Normalize the histogram
    word_hist = word_hist / np.sum(word_hist)
    # Add the histogram to the list of visual words
    test_visual_words.append(word_hist)

    # Visualize the intermediate image
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(f"Test Image {i+1}")
    plt.axis('off')
    plt.show()

    # Visualize the SIFT keypoints
    img_kp = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    plt.imshow(cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB))
    plt.title(f"SIFT Keypoints for Test Image {i+1}")
    plt.axis('off')
    plt.show()

    # Visualize the visual word occurrences
    plt.bar(range(num_clusters), word_hist)
    plt.title(f"Visual Words Histogram for Test Image {i+1}")
    plt.xlabel("Visual Word Index")
    plt.ylabel("Occurrences")
    plt.show()


# Train a SVM classifier using the visual words
classifier = SVC(kernel='linear')
classifier.fit(test_visual_words, test_labels)

# Recognize faces in the test images
predictions = []
for visual_words in test_visual_words:
    # Predict the label using the trained classifier
    label = classifier.predict([visual_words])[0]
    # Add the label to the list of predictions
    predictions.append(label)

print("Predictions:",predictions,"\n","Labels:",test_labels)
from sklearn.metrics import accuracy_score
acc = accuracy_score(test_labels, predictions)
print("accuracy is:",acc)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
y_test = test_labels
y_pred = predictions
cm = confusion_matrix(y_test, y_pred)
print("Confusion matrix:")
print(cm)
precision = precision_score(y_test, y_pred,average='macro')
print("Precision:")
print(precision)
recall = recall_score(y_test, y_pred,average='macro')
print("Recall:")
print(recall)
f1_score = f1_score(y_test, y_pred,average='macro')
print("F1 score:")
print(f1_score)



"""# BOVW method on IITJ campus dataset"""

import cv2
import numpy as np
import os
from sklearn.metrics import accuracy_score, recall_score, precision_score
from google.colab.patches import cv2_imshow
from google.colab import drive
drive.mount('/content/drive')
path = "/content/drive/MyDrive/computer_vision/project1/own_dataset_rj"
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.cluster import KMeans

files_list = []
for root, dirs, files in os.walk(path):
    for f in files:
        files_list.append((os.path.join(root, f)))

print(files_list)

train_list = []
train_label = []
test_list = []
test_label = []



for i in files_list:
    temp = i.split(".")[0]
    temp_list = temp.split("/")[-1].split("_")
    target = temp_list[1]
    image_no = temp_list[0]
    img_rem = int(image_no) % 10
    if img_rem ==0 or img_rem == 9:
        test_list.append(i)
        test_label.append(target)
    else:
        train_list.append(i)
        train_label.append(target)


train_set = set(train_label)
count1 = 0
dict_lab = {}
for i in train_set:
    dict_lab[i] = count1
    count1+=1
for i in range(len(train_label)):
    train_label[i] = dict_lab[train_label[i]]
for i in range(len(test_label)):
    test_label[i] = dict_lab[test_label[i]]


train_images = []
train_labels = []
for i in range(0, len(train_list)):

    img = cv2.imread(train_list[i])

    train_images.append(img)
    label = train_label[i]
    
    train_labels.append(label)
# Load test images and labels
test_images = []
test_labels = []
for i in range(0, len(test_list)):  
    
    img = cv2.imread(test_list[i])
    test_images.append(img)
    label = test_label[i]
    
    test_labels.append(label)


print("len of train label",len(train_labels))
print("len of train img",len(train_images))
print("len of test label",len(test_labels))
print("len of test img ",len(test_images))


import numpy as np
from sklearn.cluster import KMeans
from sklearn.svm import SVC
import cv2

# Define the number of clusters (visual words)
num_clusters = 50

# Initialize the SIFT feature detector and descriptor
sift = cv2.xfeatures2d.SIFT_create()

# Extract features from the train images
train_features = []
for img in train_images:

    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.resize(gray, (100, 100), interpolation = cv2.INTER_AREA) # resize to 80x80
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Add the descriptors to the list of features
    train_features.append(des)

# Concatenate the features into a single array
train_features = np.concatenate(train_features)

# Cluster the features into visual words
kmeans = KMeans(n_clusters=num_clusters).fit(train_features)

# Visualize the visual words
visual_words = kmeans.cluster_centers_
plt.figure(figsize=(10, 5))
for i in range(num_clusters):
    plt.subplot(5, 10, i+1)
    plt.imshow(visual_words[i].reshape((8, 16)).astype(np.uint8), cmap='gray')
    plt.axis('off')
plt.tight_layout()
plt.show()

# Extract features from the test images
test_features = []
for img in test_images:
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.resize(gray, (100, 100), interpolation = cv2.INTER_AREA) # resize to 80x80
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Add the descriptors to the list of features
    test_features.append(des)

# Convert the test features into visual words
test_visual_words = []
for i in range(len(test_images)):
    img = test_images[i]
    label = test_labels[i]
    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Detect and compute keypoints and descriptors using SIFT
    kp, des = sift.detectAndCompute(gray, None)
    # Cluster the features into visual words
    words = kmeans.predict(des)
    # Count the occurrences of each visual word
    word_hist, _ = np.histogram(words, bins=num_clusters, range=(0, num_clusters))
    # Normalize the histogram
    word_hist = word_hist / np.sum(word_hist)
    # Add the histogram to the list of visual words
    test_visual_words.append(word_hist)

    # Visualize the intermediate image
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(f"Test Image {i+1}")
    plt.axis('off')
    plt.show()

    # Visualize the SIFT keypoints
    img_kp = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    plt.imshow(cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB))
    plt.title(f"SIFT Keypoints for Test Image {i+1}")
    plt.axis('off')
    plt.show()

    # Visualize the visual word occurrences
    plt.bar(range(num_clusters), word_hist)
    plt.title(f"Visual Words Histogram for Test Image {i+1}")
    plt.xlabel("Visual Word Index")
    plt.ylabel("Occurrences")
    plt.show()


# Train a SVM classifier using the visual words
classifier = SVC(kernel='linear')
classifier.fit(test_visual_words, test_labels)

# Recognize faces in the test images
predictions = []
for visual_words in test_visual_words:
    # Predict the label using the trained classifier
    label = classifier.predict([visual_words])[0]
    # Add the label to the list of predictions
    predictions.append(label)

import numpy as np
from sklearn.metrics import accuracy_score

acc = accuracy_score(test_labels, predictions) 
print("Accuracy is",acc)

print("Predictions:",predictions,"\n","Labels:",test_labels)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
y_test = test_labels
y_pred = predictions
cm = confusion_matrix(y_test, y_pred)
print("Confusion matrix:")
print(cm)
precision = precision_score(y_test, y_pred,average='macro')
print("Precision:")
print(precision)
recall = recall_score(y_test, y_pred,average='macro')
print("Recall:")
print(recall)
f1_score = f1_score(y_test, y_pred,average='macro')
print("F1 score:")
print(f1_score)